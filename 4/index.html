<!DOCTYPE html>
<html>

<head>
    <title>My Portfolio</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        /* From https://css-tricks.com/almanac/properties/i/image-rendering/
        */
        img {
            image-rendering: auto;
            image-rendering: crisp-edges;
            image-rendering: pixelated;

            /* Safari seems to support, but seems deprecated and does the same thing as the others. */
            image-rendering: -webkit-optimize-contrast;
        }
    </style>
</head>

<body>

    <h1>Project 4: Warping and Mosaicing</h1>

        <h2>Manual Labelling</h2>

            <h3>Warping</h3>

                <p>Given two sets of four points, we can compute a "homography" that captures the projective transformation from one set of points to the other. Additional pairs of points let us compute a least-squares homography that is less sensitive to errors in the placement of individual points.</p>

                <p>To obtain a "rectification" of an image, we label four points in the image. Then we compute the homography between the labelled points and a rectangle of our choice. Applying the homography to the image produces a warped version of the image in which the region defined by the labelled points appears rectangular.</p>
            
                <img src="media/data/room_left.jpg" alt="img" width=auto height="300">
                <img src="media/out/labels_rect_room_left.jpg" alt="img" width=auto height="300">
                <img src="media/out/rect_room_left.jpg" alt="img" width=auto height="300">
                <p>[A photo of my desk <code>(room_left.jpg)</code>; with labels; warped so that the computer monitor appears rectangular.]</p>

                <img src="media/data/door.jpg" alt="img" width=auto height="300">
                <img src="media/out/labels_rect_door.jpg" alt="img" width=auto height="300">
                <img src="media/out/rect_door.jpg" alt="img" width=auto height="450">
                <p>[A photo of the door to my house <code>(door.jpg)</code>; with labels; warped so that the door appears rectangular.]</p>

                <p>For the photo of my desk, I labelled the four corners of the computer monitor and mapped these points to a 16:9 rectangle (the monitor has a 16:9 aspect ratio). For the photo of the door, I labelled the four corners of the doorframe and mapped these points to a 1:2 rectangle.</p>
            
            <h3>Mosaicing</h3>

                <p>Rather than mapping the labelled points of an image to a rectangle, we can map the labelled points of an image to corresponding points in a second image (that was taken from approximately the same point in space). Applying the resulting homography to the first image warps it to match the perspective of the second image, and combining the warped first image with the original second image produces a seamless "mosaic."</p>
                        
                <p>A homography defined by hand-picked pairs of corresponding points may be imprecise. To improve the homography, we perform gradient descent over the eight parameters of the homography. (For a particular homography, our gradient-descent loss function computes the per-pixel difference between the warped first image and the original second image.)</p>

                <img src="media/data/room_left.jpg" alt="img" width=auto height="300">
                <img src="media/data/room_right.jpg" alt="img" width=auto height="300">

                <img src="media/out/labels_room_left.jpg" alt="img" width=auto height="300">
                <img src="media/out/labels_room_right.jpg" alt="img" width=auto height="300">

                <p>[Two photos <code>room_left.jpg</code> and <code>room_right.jpg</code>; with matching labels.]</p>
                
                <p>Once a precise homography is obtained, the resulting warped first image and original second image must be combined in a way that prevents visual artifacts. We divide the combined image into three regions: one in which the warped first image is the sole contributor, one in which the original second image is the sole contributor, and one in which both images contribute. For each pixel in the region of overlap, we calculate the Manhattan distance between the pixel and each of the exclusive regions. These distances decide the weights for our weighted-average computation of the RGB values of the pixel in the combined image.</p>

                <img src="media/data/room_left.jpg" alt="img" width=auto height="400">
                <img src="media/data/room_right.jpg" alt="img" width=auto height="400">
                <img src="media/out/mosaic_room.jpg" alt="img" width=auto height="400">
                <p>[Two photos <code>room_left.jpg</code> and <code>room_right.jpg</code>; a mosaic of the two photos.]</p>

                <img src="media/data/couch_left.jpg" alt="img" width=auto height="400">
                <img src="media/data/couch_right.jpg" alt="img" width=auto height="400">
                <img src="media/out/mosaic_couch.jpg" alt="img" width=auto height="400">
                <p>[Two photos <code>couch_left.jpg</code> and <code>couch_right.jpg</code>; a mosaic of the two photos.]</p>

                <img src="media/data/plushies_left.jpg" alt="img" width=auto height="400">
                <img src="media/data/plushies_right.jpg" alt="img" width=auto height="400">
                <img src="media/out/mosaic_plushies.jpg" alt="img" width=auto height="400">
                <p>[Two photos <code>plushies_left.jpg</code> and <code>plushies_right.jpg</code>; a mosaic of the two photos.]</p>

        <h2>Automated Labelling</h2>

            <p>We can automate our code for mosaicing by writing code that automatically determines the corresponding points of a homography. Our approach is a simplified version of the approach described in ""Multi-Image Matching using Multi-Scale Oriented Patches" (Brown et al.).</p>

            <h3>Harris Corners</h3>

                <p>The project spec provides us with a <code>get_harris_corners</code> function. This function takes a grayscale image as input and outputs all integer-coordinate points that are local maximums for "corner strength". (A point has high corner strength if the derivatives of the image w.r.t. x and w.r.t. y are both large at that point.)</p>

                <img src="media/out/debug_corners1_all.jpg" alt="img" width=auto height="400">
                <img src="media/out/debug_corners2_all.jpg" alt="img" width=auto height="400">

                <p>[The results of calling <code>get_harris_corners</code> on <code>room_left.jpg</code> and <code>room_right.jpg</code>.]</p>

                <p>Calling <code>get_harris_corners</code> gives us thousands of points because the threshold for any given point being a local maximum is very low. Some points, such as the points on the corners of the computer monitor, make sense. But most of them do not correspond to visible corners. We need to eliminate most of the returned points and keep only the best ones.</p>

            <h3>Adaptive Non-Maximal Suppression</h3>

                <p>We want to keep the returned points with the greatest corner strength. However, simply keeping the greatest-strength points is not good enough, as explained by Brown et al. This naive strategy tends to keep points that are closely clustered. Instead, we want to keep points that are roughly evenly-distributed so that two overlapping images are likely to have many corresponding points in their overlap.</p>

                <p>The Adaptive Non-Maximal Suppression (ANMS) strategy calculates the "suppression radius" of each returned point. The point with the highest corner strength has an infinite suppression radius; for each other point <code>p</code>, the suppression radius of <code>p</code> is the minimum distance to a point with "significantly greater" corner strength (in our case, at least 11.1% more). ANMS keeps the 500 points with the greatest suppression radii.</p>

                <p>(It turns out that calculating suppression radii is the most computationally expensive part of automated mosaicing. I found it helpful to ignore all but the 5000 points with greatest corner strength while calculating suppression radii and deciding which points to keep.)</p>

                <img src="media/out/debug_anms1.jpg" alt="img" width=auto height="400">
                <img src="media/out/debug_anms2.jpg" alt="img" width=auto height="400">

                <p>[The results of applying ANMS to the previous images.]</p>

                <p>In the post-ANMS examples above, we can see that the points on the corners of the computer monitor and other "sensible" points remain. But most of the arbitrary-looking points are gone. Furthermore, the remaining points are distributed fairly evenly.</p>

            <h3>Feature Descriptors and Feature Matching</h3>

                <p>Once we have identified points that correspond to meaningful corners in an image, we obtain the "feature descriptor" of each point. The feature descriptor for point <code>p</code> samples the 40x40 pixels surrounding <code>p</code> and compresses them into an 8x8 grayscale image.</p>

                <p>With the post-ANMS points and feature descriptors for two overlapping images, we can now perform "feature matching" to find corresponding points between the two images. We measure the error between two feature descriptors as the squared norm of their difference, which is easily calculated in NumPy.</p>

                <p>For each post-ANMS point <code>p</code> in image <code>im1</code>, we compute the nearest neighbor of <code>p</code> in image <code>im2</code>; that is, the point <code>q1</code> in <code>im2</code> whose feature descriptor has the least error with the feature descriptor of <code>p</code>. We also compute the second-nearest neighbor <code>q2</code> of <code>p</code>.</p>

                <p>Let <code>e1</code> be the error between the f.d.s of <code>p</code> and <code>q1</code>; let <code>e2</code> be the error between the f.d.s of <code>p</code> and <code>q2</code>. From "Distinctive image features from scale-invariant keypoints" (Lowe), we know that the ratio <code>e1 / e2</code> is closely linked to whether <code>p</code> and <code>q1</code> are corresponding points. In particular, Brown et al. tell us that <code>p</code> and <code>q1</code> are overwhelmingly likely to be corresponding points when <code>e1 / e2 &lt; 0.4</code>. However, our RANSAC method for computing a least-squares homography works even if we incorrectly identify many pairs of points as corresponding, so we choose a more generous threshold of <code>e1 / e2 &lt; 0.7</code>.</p>
                
                <p>We conclude feature matching by identifying all pairs of points <code>(p, q)</code> that are "symmetrically" satisfactory; that is, <code>p</code> and <code>q</code> are each other's nearest neighbors and both points satisfy the <code>e1 / e2 &lt; 0.7</code> threshold.</p>

                <img src="media/out/debug_pairs1.jpg" alt="img" width=auto height="400">
                <img src="media/out/debug_pairs2.jpg" alt="img" width=auto height="400">

                <p>[All pairs of points identified by matching the f.d.s of <code>room_left.jpg</code> and <code>room_right.jpg</code>.]</p>

                <br>

                <img src="media/out/debug_feature1_2.jpg" alt="img" width=auto height="200">
                <img src="media/out/debug_feature2_2.jpg" alt="img" width=auto height="200">

                <p>[The f.d.s for the pair of points at the bottom-left corner of the computer monitor, labelled "2".]</p>

                <img src="media/out/debug_feature1_3.jpg" alt="img" width=auto height="200">
                <img src="media/out/debug_feature2_3.jpg" alt="img" width=auto height="200">

                <p>[The f.d.s for the pair of points at the top-right corner of the computer monitor, labelled "3".]</p>

                <img src="media/out/debug_feature1_32.jpg" alt="img" width=auto height="200">
                <img src="media/out/debug_feature2_32.jpg" alt="img" width=auto height="200">

                <p>[The f.d.s for the pair of points at the top-right corner of the yellow water bottle, labelled "32".]</p>

            <h3>RANSAC</h3>

                <p>The final step in automating our mosaicing process is to compute a least-squares homography from our pairs of corresponding points. Not all of our pairs are guaranteed to be correct, so we cannot simply use all of them in the homograpy computation.</p>

                <p>Our strategy is to repeatedly and randomly select four pairs of corresponding points. For each selection, we compute the homography <code>H</code> implied by the four pairs. Then we count the "inliers" of <code>H</code>; that is, we count how many of our pairs are correctly mapped by <code>H</code>. This computation is very quick for an individual selection, so we can iterate over thousands of random selections.</p>

                <p>After inspecting a sufficient number of selections, we choose the selection which has the maximum "inliers" count. The homography <code>H</code> for this selection is likely very close to the correct homography. We refine <code>H</code> by greedily introducing additional pairs of corresponding points to its least-squares computation until we can no longer improve the "inliers" count for our current <code>H</code>.</p>

                <p>Once we have settled on a final <code>H</code>, we proceed with warping and overlapping. Unlike manual mosaicing, we do not need to improve <code>H</code> with gradient descent.</p>

            <h3>Results</h3>

                <img src="media/out/mosaic_room.jpg" alt="img" width=auto height="400">
                <img src="media/out/autom_room.jpg" alt="img" width=auto height="400">

                <br>

                <img src="media/out/mosaic_couch.jpg" alt="img" width=auto height="400">
                <img src="media/out/autom_couch.jpg" alt="img" width=auto height="400">

                <br>

                <img src="media/out/mosaic_plushies.jpg" alt="img" width=auto height="400">
                <img src="media/out/autom_plushies.jpg" alt="img" width=auto height="400">

                <p>The results of manual (left) and automated (right) mosaicing.</p>

        <h2>Bells and Whistles</h2>

            <p>Two improvements for automated mosaicing.</p>

            <h3>Scale Invariance</h3>

                    <p>For two overlapping images with drastically different resolutions, the feature-matching process described above will not work well because feature descriptors for the larger image with appear "zoomed in" compared to feature descriptors for the smaller image. We solve this problem by sampling Harris corners from a Gaussian pyramid, as mentioned by Brown et al.</p>

                    <p>We create a Gaussian pyramid for each input image by repeatedly smoothing and downsampling the image. Lower-resolution levels in the pyramid let us capture more pixels from the original image when we compute feature descriptors. The pyramid should not be too deep, however, because the sub-pixel errors inherent to <code>get_harris_corners</code> grow enormously when we convert from the coordinates of a low-resolution level to the coordinates of the original level.</p>

                    <p>In our code for obtaining the initial points of interest, we call <code>get_harris_corners</code> on each level of a pyramid. Then we combine the results of these calls (while recording the "origin level" of each point) and proceed normally. The origin level of a point matters primarily for computing its feature descriptor.</p>

                    <img src="media/out/debug_corners1_level0.jpg" alt="img" width=auto height="400">
                    <img src="media/out/debug_corners1_level1.jpg" alt="img" width=auto height="400">

                    <p>[Harris corners for the zeroth and first levels of the Gaussian pyramid derived from a doubled-resolution <code>room_left.jpg</code>.]</p>
                    
                    <img src="media/out/autom_plushies.jpg" alt="img" width=auto height="400">

                    <p>[The automated mosaic between <code>room_left.jpg</code> and <code>room_right.jpg</code>; the automated mosaic between a doubled-resolution <code>room_left.jpg</code> and the original <code>room_right.jpg</code>.]</p>

                    <p>We can see that the automated mosaic becomes slightly worse when we introduce a doubled-resolution <code>room_left.jpg</code>. This makes sense because our reliance on the first level of the Gaussian pyramid effectively doubles the errors of <code>get_harris_corners</code>.</p>

            <h3>Unordered Set Processing</h3>

                    <p>We can use feature matching not just to find corresponding points between two overlapping images, but also to determine whether two images overlap at all. We define the constant value <code>min_pairs = 15</code>. If feature matching between images <code>im1</code> and <code>im2</code> yields less than <code>min_pairs</code> pairs of corresponding points, then it is very likely that <code>im1</code> and <code>im2</code> do not overlap.</p>

                    <p>Given an unordered set of images, we remove the two images for which feature matching yields the most corresponding points across all pairs of images. Then we combine these images via automated mosaicing and append the result to the set. We repeat this process until no pair of images in the set has at least <code>min_pairs</code> pairs of corresponding points.</p>

                    <img src="media/out/autom_unordered0.jpg" alt="img" width=auto height="400">
                    <img src="media/out/autom_unordered1.jpg" alt="img" width=auto height="400">

                    <br>

                    <img src="media/out/autom_unordered2.jpg" alt="img" width=auto height="400">
                    <img src="media/out/autom_unordered3.jpg" alt="img" width=auto height="400">
                    
                    <p>[The result of processing a shuffled list containing the two room photos, the two couch photos, the two plushie photos, and the door photo.]</p>

                    <p>In the results above, we can see that <code>door.jpg</code>, which does not overlap with any of the other input images, is unchanged.</p>
 </body>
 </html>